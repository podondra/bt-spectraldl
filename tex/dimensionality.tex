\chap Dimensionality Reduction

After the preprocessing methods mentioned in above sections each spectrum
is a point in 140-dimensional space.
To better understant the data \glref{PCA} and \glref{t-SNE} dimensionality
reduction algorithms are applied to reduce each point to 2-dimensional space
which can be visualized as scatter plot.

\sec PCA

Principal Component Analysis is statistical technique to tranform a number
of possibly correlated variables into a smaller number of variables
called principal components. \cite[pca]

\midinsert \clabel[pca-plot]{PCA dataset visualization}
\picw=15cm \cinspic img/pca.png
\caption/f On the left size is scatter plot with first two principal
components of the original dataset. The plot more that difference in shape
show difference in fluxes values.
Right plot displays result of PCA applied to scaled variant of the dataset.
After such preprocessing mehtod absorption spectra are oriented in left part
of the plot, emission spectra are on the other side and double-peak spectra
are spread across the whole plot.
\endinsert

Left plot in figure~\ref[pca-plot] displays first and second principal
component of original dataset.
After further analysis the plot express more the intensities in spectra's
fluxes than the shape.
The points far from the dense area in middle left have high intense fluxes.
But in this work the difference between intesities in fluxes is not interesting.

The other plot in figure~\ref[pca-plot] shows dataset with supressed intensities
so that the only feature should be the shape of each spectra
(spectra are classified according to their shapes see chapter~\ref[ondrejov].

The scatter plot then expresses the structure of the dataset clearly.
Absroption spectra are on the left side
while emission spectra are mostly on the other side.
Double-peak spectra are spread across the whole plot.
This may implies that the emission and absorption spectra can be separable
by linear classifier.
But the double-peak spectra are mixed up with the other classes so
hopefully a deep neural network can find such representation that all
classes are separable.

\sec t-SNE

T-Distributed Stochastic Neighbor Embedding visualizes high-dimensional data
by giving each point a location in a two or three dimensional map.
It is variant of Stochastic Neighbor Embedding.
Unlike PCA, which is linear technique that focus on keeping the low-dimensional
representations of dissimilar points far apart,
t-SNE is capable of capturing both global and local structure.
\cite[tsne]

\midinsert \clabel[tsne-plot]{t-SNE dataset visualization}
\picw=15cm \cinspic img/tsne.png
\caption/f TODO
\endinsert
