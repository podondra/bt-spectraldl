\chap Machine Learning

Machine learning is subfield of artificial intelligence \cite[russell10].
Algorithms in machine learning allow computer programs to learn from data
\cite[goodfellow16].
Samuel Arthur proposed this famous statement about machine learning in
\cite[samuel95]:
``{\em Programming computers to learn from experience should eventually
eliminate the need for much of this programming effort.}''
Formal and widely used definition is provided by Tom Mitchell in
\cite[mitchell97]:
``{\em A computer program is said to learn from
experience $E$ with respect to some class of tasks $T$ and performance measure
$P$, if its performance at tasks in $T$, as measured by $P$, improves with
experience $E$.}''.

Therefore, instead of hardcoding the desired model directly into program,
data are feeded into machine learning algorithm which develops its own model.
This is called {\bf data-driven approach} since it depends on providing the
algorithm with vast amount of data. \cite[cs231n]

For example, considering the image classification program. It would be
challenging to hardcode into program how general dog looks. Machine learning
algorithm in combination with data-driven approach would take large collection
of dog's images, feed them into program and let it develop its own
notion of what a dog looks like.

Commonly, machine learning is divided into {\bf supervised} and
{\bf unsupervised} learning.
In supervised learning, there is a data set and its corresponding output values.
Supervised algorithms are used for solving {\bf classification} or
{\bf regression} tasks.
In classification inputs are assigned from a set of discrete values.
On contrary, regression predicts ouputs from continuos range.
Unsupervised learning allows to solve problems where is no or little idea about
the result. \cite[goodfellow16]

\sec Deep Learning

Conventional machine learning techniques were limited in ability to process
raw natural data.
Machine learning algorithm required careful design of feature extractor that
tranformed the raw data into suitable feature vectors from which the learning
subsystem could classify patterns in the input.

Deep learning methods are representation learning methods with multiple levels
of representation obtained by composing simple but non-linear modules.
With the composition of enough such transformation higher layers of
representation amplify aspects of the input that can be important for
discrimination.
The key is that these layers of features are not designed by humans but
learned from data. \cite[deep-learning]

\secc Feedforward Neural Networks

Many applications of deep learning use feedforward neural network
architectures.
To go from one layer to the next a set of units
compute a weighted sum of their inputs from previous layer and apply
non-linear function to the result.
Units that are not in the input or output layer are called hidden units.
These hidden layers of a multilayer neural network can distort the input
space to make the classes linearly separable.

\medskip \clabel[neural-network]{Feedforward neural network}
\picw=7.5cm \cinspic img/neural-network.png
\caption/f Feedforward neural network with 4 {\bf fully connected} layers.
The input layer has 3 units followed 2 hidden layers with 4 and 3 units.
Ouput layer contains 2 units.
\medskip

\secc Convolutional Neural Networks

Convolutional neural networks are one particular type of deep feedforward
network that is much easier to train and generalize much better than
fully connected networks.

These networks are designed to process data in form of multiple arrays.
For instance, 1 dimensional signals or 2 dimensional images.
They take advantage of four properties:

\begitems
* local connections,
* shared weights,
* pooling,
* use of many layers.
\enditems

Typical convolutional neural network is structured as series of stages.
First stages are composed of convolutional layers and pooling layers.
Units in convolutional layer maps to next layer through several filters.
These results are passed through a non-linearity.
Nowadays, the most widely used is rectified linear unit:

$$ f(z) = \max(z, 0) \eqmark $$

The reasons for this architecture are that local groups of values are highly
correlated and motifs can appear in any part of image or signal.
Mathematically, the filtering operation is discrete convolution, hence the name.

Pooling layers are used to merge semantically similar features into one.
This layer usually computes maximum of a local patch of units.
Thereby, they reduce the dimensions of the representation and invariance
to small shifts. \cite[deep-learning]
