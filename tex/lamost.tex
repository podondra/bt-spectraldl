\chap LAMOST Classification

This chapter gathers all knowledge from previous chapters and classify
LAMOST Data Release 1
which contains spectra from pilot and first year surveys
(see table~\ref[lamost]).
Firstly, architecture and training of a deep neural network is described
followed by evaluation and visualizations of results.

\sec Neural Network Architecture

A feedforward neural network and a convolutional neural network were design.
After evaluation on test set the convolutional network
was chosen for final classification.

Design choices follow guide provided by \cite[cs231n].
The main idea is to build rather deeper neural network
which has a lot of representation power
and use dropout (see section~\ref[dropout]) to avoid overfitting.
Next sections describe the architectures.

\label[dropout]
\secc Dropout

{\bf Dropout} is technique for addressing problem of {\bf overfitting}.
The key idea is to randomly drop units from the neural network
during training.
During training dropout created different smaller networks by blocking
units of a big one.
This prevent units from co-adaption
and at test time the neural network with all units but smaller weights
is average of all the smaller networks from training.
\cite[dropout]

\secc Feedforward Network

The feedforward network has input layer with 140 units.
Then there are 5 hidden layers with 512 units
and the last output layer has 3 units
with softmax activation function~\cite[nielsen2015]
because there 3 target classes.

Every hidden layer's activation function is \glref{ReLU}
(see section \ref[convnets]).
During training dropout (see subsection \ref[dropout]) is applied
with a unit dropout probability set to 0.5 as recommeded by \cite[dropout].

\secc Convolutional Network

Architecture of convolutional network for spectra classification in this work
is inspired primarily by
VGGNet \cite[vggnet], AlexNet \cite[alexnet] and ZFNet \cite[zfnet].
These network are design to process three dimensional images
counting \glref{RGB} color channels.
Spectrum can be understand as one dimensional image.
Therefore the architecture need to be suited to this difference.

Sketch of architecture diagram is in figure~\ref[convnet].
The input layer has 140 units
and output layer has 3 units with softmax activation~\cite[nielsen2015].
In the middle there are convolutional layers
all with filter size 3 pixels and no padding.
First 2 layers have 64 of the filters.
Second 2 layers have 128 of them and the last 2 layers have 256 filters.
After each pair of convolutional layers is a max-pooling layes
of size 2 pixel with stride 2.
The last max-pooling layer is followed are 2 fully-connected layer
with 512 units each
and dropout with probability 0.5 \cite[dropout] applied in training.
All hidden layers use \glref{ReLU} activation function.

\midinsert \clabel[convnet]{Convnet architecture}
\picw=5cm \cinspic img/convnet.png
\caption/f TODO
\endinsert

\sec Training Details

TODO
\cite[adam]

\midinsert \clabel[confusion-matrices]{Confusion matrices}
\picw=15cm \cinspic img/confusion-matrices.png
\caption/f TODO
\endinsert

\midinsert \clabel[convnet-training]{Training accuracy and loss}
\picw=15cm \cinspic img/convnet-training.png
\caption/f TODO
\endinsert

\secc Dataset Split

This section shows how the Ond≈ôejov dataset is split into
training, validation and test set.
These sets are required for training, tuning and evaluating any neural network.
All split are done as stratified sampling so that the distribution of
samples' number in a class is kept across sets.

Test set on which neural networks are evaluated contains 10\% of all data.
Validation set which serves for hyperparameter and architecture optimization
is 20\% of remaining data.
Training set is composed from the rest of data
and its purpose is for training networks' weights contains 80\% of all data.
Exact numbers of spectra in each set is in table~\ref[dataset-split-table].

\midinsert \clabel[dataset-split-table]{Dataset split table}
\ctable{lrrr}{
    \hfil set  & emission & absorption & double-peak \hfil \crl \tskip4pt
    train      &   3\,817 &     4\,393 & 1\,104 \cr
    validation &      954 &     1\,099 &    276 \cr
    test       &      530 &        611 &    153 \cr
}
\caption/t Exact numbers of samples in train, validation and test set
divided according to emission, absorption and double-peak classes.
\endinsert

\secc SMOTE Balancing

\glref{SMOTE} is shortcut for
{\bf Synthetic Minority Over-sampling Technique}.
It is over-sampling approach in which the minority class is
over-sampled by creating {\bf synthetic} samples.
A new sample is created along line from a sample to its all or any $k$
nearest neighbors from same class.
Difference between feature vectors of sample under consideration
and nearest neighbor is taken.
It is multiply by random number between 0 and 1.
Finally it is added to the sample.
\cite[smote]

Scikit-learn contribution Python package {\bf imbalanced-learn} \cite[imblearn]
in version 0.2.1:

\begtt
import imblearn.over_sampling

N_CLASSES = 3
smote = imblearn.over_sampling.SMOTE()
for _ in range(N_CLASSES - 1):
    X, y = smote.fit_sample(X, y)
\endtt

where {\tt X} and {\tt y}.

\midinsert \clabel[imbalanced-cm.png]{Imbalanced confusion matrix}
\picw=10cm \cinspic img/imbalanced-cm.png
\caption/f TODO
\endinsert

\sec Results and Visualizations

TODO

\sec Performance and Scalability

TODO
